# ğŸ§  HiveMind v3.0 â€” The Relational Cognitive Engine
**HiveMind v3.0 â€” Äá»™ng CÆ¡ Nháº­n Thá»©c Quan Há»‡**

> **A Complete Architectural Overhaul. Coming Soon.**
> **Sá»± Thay Äá»•i Kiáº¿n TrÃºc ToÃ n Diá»‡n. Sáº¯p Ra Máº¯t.**

<div align="center">
  
  [![Stars](https://img.shields.io/github/stars/shynlee04/hivemind-plugin?style=social)](https://github.com/shynlee04/hivemind-plugin/stargazers)
  [![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
  [![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue.svg)](https://www.typescriptlang.org/)
  
  *From Flat-File Fallacy to Tier-1 Enterprise Agentic Framework*
  *Tá»« áº¢o TÆ°á»Ÿng File Pháº³ng Ä‘áº¿n Framework Agentic Doanh Nghiá»‡p Háº¡ng Nháº¥t*

</div>

---

## ğŸŠ Lá»i Cáº£m Æ n / A Message from the Heart

**ChÃ o báº¡n! Xin chÃ o! Hello friend!**

NhÃ¢n dá»‹p Táº¿t NguyÃªn ÄÃ¡n sáº¯p Ä‘áº¿n gáº§n táº¡i Viá»‡t Nam ğŸ§§, tÃ´i muá»‘n gá»­i lá»i cáº£m Æ¡n chÃ¢n thÃ nh Ä‘áº¿n cá»™ng Ä‘á»“ng tuyá»‡t vá»i nÃ y.

As Lunar New Year (Táº¿t NguyÃªn ÄÃ¡n) approaches here in Vietnam ğŸ§§, I find myself reflecting on this incredible journey. What started as a simple script to help me manage AI context has grown into something far more ambitiousâ€”and I couldn't have done it without this amazing community.

**Cáº£m Æ¡n báº¡n ráº¥t nhiá»u! / Thank you!**

Nhá»¯ng ngÃ´i sao, pháº£n há»“i, vÃ  sá»± kiÃªn nháº«n cá»§a báº¡n Ä‘Ã£ tiáº¿p sá»©c cho dá»± Ã¡n nÃ y. TÃ´i Ä‘Ã£ dÃ nh nhiá»u thÃ¡ng Ä‘á»ƒ kiáº¿n trÃºc láº¡i thá»© gÃ¬ Ä‘Ã³ mÃ  tÃ´i tin ráº±ng sáº½ thay Ä‘á»•i cÃ¡ch chÃºng ta nghÄ© vá» viá»‡c quáº£n lÃ½ ngá»¯ cáº£nh AI.

Your stars, your feedback, your patience with the bugsâ€”it all fuels this passion project. I've been heads-down for months architecting something that I truly believe will change how we think about AI session governance.

**Äiá»u nÃ y xá»©ng Ä‘Ã¡ng Ä‘á»ƒ chá» Ä‘á»£i. / This is worth the wait.**

---

## ğŸ”¥ Äiá»u GÃ¬ LÃ m v3.0 CÃ¡ch Máº¡ng? / What Makes v3.0 Revolutionary?

Giáº£i phÃ¡p "bá»™ nhá»›" AI hiá»‡n táº¡i? Há» Ä‘ang Ä‘á»• vÄƒn báº£n vÃ o file markdown vÃ  hy vá»ng LLM tá»± tÃ¬m tháº¥y nhá»¯ng gÃ¬ cáº§n thiáº¿t. ÄÃ³ khÃ´ng pháº£i lÃ  bá»™ nhá»›â€”Ä‘Ã³ lÃ  **nghÄ©a Ä‘á»‹a**.

The current landscape of AI "memory" solutions? They're dumping text into markdown files and hoping the LLM magically finds what it needs. That's not memoryâ€”that's a **graveyard**.

**HiveMind v3.0** giá»›i thiá»‡u **Äá»™ng CÆ¡ Nháº­n Thá»©c Quan Há»‡** / introduces the **Relational Cognitive Engine**:

### ğŸŒ³ Kiáº¿n TrÃºc `.hivemind` Má»›i / The New `.hivemind` Architecture

```
.hivemind/
â”œâ”€â”€ âš™ï¸ system/                    # CORE GOVERNANCE & REGISTRY
â”‚   â”œâ”€â”€ config.json               # TTS thresholds, 80% split limits
â”‚   â””â”€â”€ manifest.json             # Master Index (UUID mappings)
â”‚
â”œâ”€â”€ ğŸ§  graph/                     # RELATIONAL GRAPH DATABASE
â”‚   â”œâ”€â”€ trajectory.json           # Dynamic "Read-Head" for intent shifts
â”‚   â”œâ”€â”€ plans.json                # Epics & Phases
â”‚   â”œâ”€â”€ tasks.json                # Execution Graph (Task â†’ Sub-Task)
â”‚   â””â”€â”€ mems.json                 # Multi-shelf semantic knowledgebase
â”‚
â”œâ”€â”€ â±ï¸ sessions/                  # NON-DISRUPTIVE SDK CONTAINERS
â”‚   â”œâ”€â”€ active/session_main.json  # Token pressure tracking
â”‚   â””â”€â”€ swarms/                   # Headless Actor Model sessions
â”‚
â””â”€â”€ ğŸ“œ artifacts/                 # HUMAN-READABLE OUTPUTS
    â”œâ”€â”€ dashboards/               # Interactive 3D Brain-Map
    â””â”€â”€ synthesis/                # Auto-generated reports
```

ChÃºng tÃ´i chuyá»ƒn tá»« file markdown pháº³ng sang **CÆ¡ Sá»Ÿ Dá»¯ Liá»‡u Äá»“ Thá»‹ Quan Há»‡** vá»›i UUID vÃ  KhÃ³a Ngoáº¡i. KhÃ´ng cÃ²n dá»¯ liá»‡u má»“ cÃ´i. KhÃ´ng cÃ²n lÃ£ng phÃ­ token.

We are moving from flat markdown files to a **Relational Graph Database** with UUIDs and Foreign Keys. No more orphaned data. No more token waste.

### âš¡ "Repomix-for-State" â€” TrÃ¬nh BiÃªn Dá»‹ch Ngá»¯ Cáº£nh / Context Compiler

Thay vÃ¬ hy vá»ng LLM Ä‘á»c file, chÃºng tÃ´i **biÃªn dá»‹ch ngá»¯ cáº£nh má»™t cÃ¡ch láº­p trÃ¬nh**:

Instead of hoping the LLM reads files, we **programmatically compile context**:

1. **Write-Through (CÃ´ng cá»¥ = Chi Thá»©c)**: LLM sá»­ dá»¥ng cÃ´ng cá»¥ Ä‘á»ƒ thay Ä‘á»•i tráº¡ng thÃ¡i
   **Write-Through (Tools = Conscious Limbs)**: LLM uses tools to mutate state
   
2. **Read-Auto (Hooks = Há»‡ Tháº§n Kinh)**: Ngá»¯ cáº£nh tá»± Ä‘á»™ng inject qua OpenCode SDK
   **Read-Auto (Hooks = Subconscious Nervous System)**: Context injects automatically via OpenCode SDK

**Káº¿t quáº£**: KhÃ´ng lÃ£ng phÃ­ token cho tool calls Ä‘á»c dá»¯ liá»‡u. Ngá»¯ cáº£nh quan há»‡ tinh khiáº¿t, táº¥t Ä‘á»‹nh.
**Result**: Zero token waste on tool calls for reading. Pure, deterministic, relational context.

### ğŸ¯ CÃ¡c MÃ´ HÃ¬nh TiÃªu Chuáº©n NgÃ nh / Industry-Standard Paradigms

- **CQRS**: TÃ¡ch biá»‡t Ghi vÃ  Äá»c / Command Query Responsibility Segregation
- **Graph-RAG**: Duy trÃ¬ quan há»‡ phÃ¢n cáº¥p (khÃ´ng pháº£i cosine similarity trÃªn file cháº¿t)
  Hierarchical relationships preserved (not cosine similarity on dead files)
- **Actor Model**: Session swarms cho nghiÃªn cá»©u ná»n / Session swarms for headless background research
- **Time-to-Stale (TTS)**: Tá»± Ä‘á»™ng dá»n dáº¹p ngá»¯ cáº£nh cháº¿t / Automatic pruning of dead context

---

## ğŸ‘€ Sneak Peek: The Screens

<div align="center">

### Screen 1: The Cognitive Graph Architecture
*How we finally escaped the Flat-File Fallacy / CÃ¡ch chÃºng tÃ´i thoÃ¡t khá»i áº¢o TÆ°á»Ÿng File Pháº³ng*

[View Screen 1 â†’](./docs/stitch-screens/screen-01.html)

---

### Screen 2: Relational Directory Tree
*Every entity has a UUID and Foreign Keys. No more orphans. / Má»—i thá»±c thá»ƒ cÃ³ UUID vÃ  KhÃ³a Ngoáº¡i. KhÃ´ng cÃ²n má»“ cÃ´i.*

[View Screen 2 â†’](./docs/stitch-screens/screen-02.html)

---

### Screen 3: Schematic Entity Relationships
*The mathematical topology that makes programmatic traversal possible*

[View Screen 3 â†’](./docs/stitch-screens/screen-03.html)

---

### Screen 4: The Repomix I/O Flow
*Write-Through Tools + Read-Auto Hooks = The 2026 Standard*

[View Screen 4 â†’](./docs/stitch-screens/screen-04.html)

---

### Screen 5: Context Compiler Deep Dive
*How `cognitive-packer.ts` purifies and compresses state into XML*

[View Screen 5 â†’](./docs/stitch-screens/screen-05.html)

---

### Screen 6: SDK Hook Injection
*The invisible nervous system: `experimental.chat.messages.transform`*

[View Screen 6 â†’](./docs/stitch-screens/screen-06.html)

---

### Screen 7: Session Swarm Architecture
*Actor Model for headless background agents*

[View Screen 7 â†’](./docs/stitch-screens/screen-07.html)

---

### Screen 8: The 80% Rule & Non-Disruptive Splits
*Graceful session splitting without losing context*

[View Screen 8 â†’](./docs/stitch-screens/screen-08.html)

---

### Screen 9: Tool Consolidation Strategy
*From 14 unwired tools to 7 wired super-tools*

[View Screen 9 â†’](./docs/stitch-screens/screen-09.html)

---

### Screen 10: Testing & Verification Matrix
*84+ assertions, zero regressions, complete confidence*

[View Screen 10 â†’](./docs/stitch-screens/screen-10.html)

---

### Screen 11: Migration Roadmap
*6-phase overhaul from v2.6.0 to v3.0.0*

[View Screen 11 â†’](./docs/stitch-screens/screen-11.html)

</div>

---

## ğŸ¯ The God Prompts (CÃ¢u Lá»‡nh "Tháº§n") / How We Build This

We're not asking AI to "refactor storage." We give them **systematic boundaries**:

### Prompt 1: Graph Database Schemas
```markdown
Define strict TypeScript Zod Schemas for cognitive entities:
- PlanNode: { id, SOT_symlink, title, status }
- PhaseNode: { id, parent_plan_id, title, status }
- TaskNode: { id, parent_phase_id, type, status }
- MemNode: { id, origin_task_id, shelf, staleness_stamp }
- TrajectoryNode: { active_plan_id, active_phase_id, active_task_ids[] }
```

### Prompt 2: The Cognitive Packer
```markdown
Create cognitive-packer.ts (the "Repomix-for-State"):
1. Read trajectory.json for the "Read-Head"
2. Traverse plans.json, tasks.json, mems.json
3. Apply TTS filtering (72h staleness)
4. Compress to <hivemind_state> XML
```

### Prompt 3: SDK Hook Injection
```markdown
Implement experimental.chat.messages.transform:
1. Call packCognitiveState(sessionID)
2. Inject XML as synthetic message part
3. Append Pre-Stop Gate Checklist
```

---

## ğŸ“Š By The Numbers / Con Sá»‘ NÃ³i LÃªn Táº¥t Cáº£

| Metric | v2.6.0 | v3.0.0 (Target) |
|--------|--------|-----------------|
| **Test Assertions** | 986 | 1200+ |
| **Dead Code Lines** | 2,169 | 0 |
| **Graph Nodes** | 0 (flat files) | âˆ (relational) |
| **Context Precision** | ~60% | ~95% |
| **Token Waste** | High | Near Zero |

---

## ğŸš€ What's Next? / Tiáº¿p Theo LÃ  GÃ¬?

**Coming in Q1 2026:**

- âœ… Phase 1: Graph Schemas & Dumb Tool Diet
- âœ… Phase 2: Cognitive Packer  
- ğŸ”„ Phase 3: SDK Hook Injection (In Progress / Äang Thá»±c Hiá»‡n)
- â³ Phase 4: .hivemind Graph Migration
- â³ Phase 5: Tool Consolidation
- â³ Phase 6: Testing & Verification

---

## ğŸ’ A Personal Note / Lá»i TÃ¢m Sá»±

*Táº¿t is coming. The streets of Vietnam are filling with apricot blossoms and the smell of bÃ¡nh chÆ°ng being prepared. It's a time of renewal, of leaving behind what no longer serves us, and stepping into the new year with clarity and purpose.*

*Táº¿t Ä‘ang Ä‘áº¿n gáº§n. ÄÆ°á»ng phá»‘ Viá»‡t Nam Ä‘ang trÃ n ngáº­p sáº¯c hoa mai vÃ  mÃ¹i thÆ¡m cá»§a bÃ¡nh chÆ°ng. ÄÃ¢y lÃ  thá»i Ä‘iá»ƒm Ä‘á»•i má»›i, Ä‘á»ƒ láº¡i nhá»¯ng gÃ¬ khÃ´ng cÃ²n phá»¥c vá»¥ chÃºng ta, vÃ  bÆ°á»›c vÃ o nÄƒm má»›i vá»›i sá»± rÃµ rÃ ng vÃ  má»¥c Ä‘Ã­ch.*

**That's exactly what v3.0 represents.**
**ÄÃ³ chÃ­nh xÃ¡c lÃ  nhá»¯ng gÃ¬ v3.0 Ä‘áº¡i diá»‡n.**

We're leaving behind the chaos of flat files. We're embracing relational structure, deterministic context, and enterprise-grade architecture. 

ChÃºng tÃ´i Ä‘ang tá»« bá» sá»± há»—n loáº¡n cá»§a file pháº³ng. ChÃºng tÃ´i Ä‘ang Ä‘Ã³n nháº­n cáº¥u trÃºc quan há»‡, ngá»¯ cáº£nh táº¥t Ä‘á»‹nh, vÃ  kiáº¿n trÃºc háº¡ng doanh nghiá»‡p.

**This isn't just an update. It's a transformation.**
**ÄÃ¢y khÃ´ng chá»‰ lÃ  cáº­p nháº­t. ÄÃ¢y lÃ  sá»± biáº¿n Ä‘á»•i.**

---

<div align="center">

### â­ Star this repo to stay updated! / HÃ£y star repo nÃ y Ä‘á»ƒ nháº­n cáº­p nháº­t!

**HiveMind v3.0 â€” Making AI Memory Actually Work**
**HiveMind v3.0 â€” LÃ m cho Bá»™ Nhá»› AI Thá»±c Sá»± Hoáº¡t Äá»™ng**

*Built with â¤ï¸ in Vietnam ğŸ‡»ğŸ‡³*
*ÄÆ°á»£c xÃ¢y dá»±ng vá»›i â¤ï¸ táº¡i Viá»‡t Nam ğŸ‡»ğŸ‡³*

</div>
